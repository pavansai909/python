{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GooEubScAtGS"
      },
      "source": [
        "<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-nl74pjw6Hy"
      },
      "source": [
        "# Python Data Cleaning: Basics II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0LiYra_ZGrf"
      },
      "source": [
        "## 1.0 Importing our Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UtnqOM71DRhS"
      },
      "outputs": [],
      "source": [
        "# Importing the Pandas Library\n",
        "#\n",
        "import pandas as pd\n",
        "\n",
        "# Importing the Numpy Library\n",
        "#\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMDkx0IpxCCR"
      },
      "source": [
        "## 1.1 Validity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O2gayc6ew2qT"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number</th>\n",
              "      <th>Position</th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>College</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Avery Bradley</th>\n",
              "      <td>0.0</td>\n",
              "      <td>PG</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6-2</td>\n",
              "      <td>Texas</td>\n",
              "      <td>7730337.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jae Crowder</th>\n",
              "      <td>99.0</td>\n",
              "      <td>SF</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6-6</td>\n",
              "      <td>Marquette</td>\n",
              "      <td>6796117.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>John Holland</th>\n",
              "      <td>30.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6-5</td>\n",
              "      <td>Boston University</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R.J. Hunter</th>\n",
              "      <td>28.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6-5</td>\n",
              "      <td>Georgia State</td>\n",
              "      <td>1148640.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jonas Jerebko</th>\n",
              "      <td>8.0</td>\n",
              "      <td>PF</td>\n",
              "      <td>29.0</td>\n",
              "      <td>6-10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shelvin Mack</th>\n",
              "      <td>8.0</td>\n",
              "      <td>PG</td>\n",
              "      <td>26.0</td>\n",
              "      <td>6-3</td>\n",
              "      <td>Butler</td>\n",
              "      <td>2433333.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Raul Neto</th>\n",
              "      <td>25.0</td>\n",
              "      <td>PG</td>\n",
              "      <td>24.0</td>\n",
              "      <td>6-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>900000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tibor Pleiss</th>\n",
              "      <td>21.0</td>\n",
              "      <td>C</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7-3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2900000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jeff Withey</th>\n",
              "      <td>24.0</td>\n",
              "      <td>C</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7-0</td>\n",
              "      <td>Kansas</td>\n",
              "      <td>947276.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NaN</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>458 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Number Position   Age Height            College     Salary\n",
              "Name                                                                     \n",
              "Avery Bradley     0.0       PG  25.0    6-2              Texas  7730337.0\n",
              "Jae Crowder      99.0       SF  25.0    6-6          Marquette  6796117.0\n",
              "John Holland     30.0       SG  27.0    6-5  Boston University        NaN\n",
              "R.J. Hunter      28.0       SG  22.0    6-5      Georgia State  1148640.0\n",
              "Jonas Jerebko     8.0       PF  29.0   6-10                NaN  5000000.0\n",
              "...               ...      ...   ...    ...                ...        ...\n",
              "Shelvin Mack      8.0       PG  26.0    6-3             Butler  2433333.0\n",
              "Raul Neto        25.0       PG  24.0    6-1                NaN   900000.0\n",
              "Tibor Pleiss     21.0        C  26.0    7-3                NaN  2900000.0\n",
              "Jeff Withey      24.0        C  26.0    7-0             Kansas   947276.0\n",
              "NaN               NaN      NaN   NaN    NaN                NaN        NaN\n",
              "\n",
              "[458 rows x 6 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1: Irrelevant Data\n",
        "# Irrelevant data are those that are not actually needed, and don’t fit under \n",
        "# the context of the problem we’re trying to solve. \n",
        "# For example, we will drop the Team and Weight columns from the dataset below\n",
        "# since we will not need them in our analysis\n",
        "# \n",
        " \n",
        "# Making the dataframe from csv file \n",
        "data_df = pd.read_csv(\"http://bit.ly/MSDS-NBADataset\", index_col =\"Name\" ) \n",
        "data_df\n",
        "\n",
        "# Dropping the irrelevant columns i.e. Team and Weight\n",
        "# Those values were dropped since axis was set equal to 1 and \n",
        "# the changes were made in the original data frame since inplace was True.\n",
        "data_df.drop([\"Team\", \"Weight\"], axis = 1, inplace = True) \n",
        "  \n",
        "# # Display the resulting dataframe\n",
        "data_df  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iEgdxIlDxdUW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Nairobi     \n",
              "1      Machakos       \n",
              "2               Kisumu\n",
              "3        Nakuru       \n",
              "4              Naroko \n",
              "Name: County, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2: Syntax Errors\n",
        "# We can also remove any syntax error than we find in our records.\n",
        "# Remove white spaces: Extra white spaces at the beginning or the end of a string should be removed. \n",
        "# Pad strings: Strings can be padded with spaces or other characters to a certain width i.e. 313 => 000313 (6 digits). \n",
        "# Let's remove use the str.strip function on the respective column name to strip the leading and trailing space \n",
        "# \n",
        "\n",
        "# Creating the DataFrame to be used\n",
        "df1 = {\n",
        "    'County':['     Nairobi     ', ' Machakos       ', ' Kisumu', 'Nakuru       ', 'Naroko '],\n",
        "   'Score':[73, 83, 75, 84, 61]}\n",
        " \n",
        "df1 = pd.DataFrame(df1,columns=['County','Score'])\n",
        "\n",
        "# Displaying the resulting dataframe\n",
        "df1['County'] #use .str.strip() to remove spaces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ClA86U5UXD1y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     Nairobi\n",
              "1    Machakos\n",
              "2      Kisumu\n",
              "3      Nakuru\n",
              "4      Naroko\n",
              "Name: County, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2: Syntax Errors\n",
        "# We can use the str.strip function on the respective column name to strip the leading and trailing spaces  \n",
        "# \n",
        "\n",
        "df1['County'] = df1['County'].str.strip()\n",
        "\n",
        "\n",
        "# Displaying the resulting dataframe\n",
        "df1['County']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tj_-wOu4WlS2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>County</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nairobi</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Machakos</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kisumu</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nakuru</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Naroko</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     County  Score\n",
              "0   Nairobi     73\n",
              "1  Machakos     83\n",
              "2    Kisumu     75\n",
              "3    Nakuru     84\n",
              "4    Naroko     61"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 3: Syntax Errors\n",
        "# We can also use str.replace() function on the respective column to strip all the spaces \n",
        "# \n",
        "\n",
        "df1['County'] = df1['County'].str.replace(\" \",\"\")\n",
        "\n",
        "# Displaying the resulting dataframe\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QrOLB6WXUniz"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>County</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nairobi</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Machakos</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kisumu</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nakuru</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Narok</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     County  Score\n",
              "0   Nairobi     73\n",
              "1  Machakos     83\n",
              "2    Kisumu     75\n",
              "3    Nakuru     84\n",
              "4     Narok     61"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 4: \n",
        "# Fix typos: Strings can be entered in many different ways, and no wonder they can have mistakes.\n",
        "#\n",
        "\n",
        "# If you want to replace certain words - \"Naroko\" with \"Narok\"\n",
        "df1['County'] = df1['County'].str.replace('Naroko', 'Narok')\n",
        "\n",
        "df1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7Dgv6QeG-tw"
      },
      "source": [
        "### <font color=\"green\">1.1 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "q7UiUX92HD7P"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Country Name\n",
              "World                                       59347202\n",
              "Low & middle income                         59206053\n",
              "IDA & IBRD total                            57616609\n",
              "Fragile and conflict affected situations    43112386\n",
              "Pre-demographic dividend                    41309974\n",
              "Name: Value, dtype: int64"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge 1\n",
        "# We have been given the following dataset to work with\n",
        "#url = 'http://bit.ly/MSOriginOfRefugees'\n",
        "# and we will be answering the following question;\n",
        "# Which territories of origin had the highest no. of refugees from the year 2005 - 2010?\n",
        "# Provide the relevant data for your analysis below. \n",
        "# NB: We are only expected to clean our data. Once finished compare answers with other classmates. \n",
        "#\n",
        "df = pd.read_csv('data_csv.csv')\n",
        "df\n",
        "year = df[(df['Year']>= 2005)&(df['Year']<=2010)]\n",
        "year\n",
        "year.groupby(['Country Name'])['Value'].sum().sort_values(ascending = False).head(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Lq8ktZgxHIww"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Team</th>\n",
              "      <th>Number</th>\n",
              "      <th>Position</th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>College</th>\n",
              "      <th>Salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Avery Bradley</td>\n",
              "      <td>Boston Celtics</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PG</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6-2</td>\n",
              "      <td>180.0</td>\n",
              "      <td>Texas</td>\n",
              "      <td>7730337.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jae Crowder</td>\n",
              "      <td>Boston Celtics</td>\n",
              "      <td>99.0</td>\n",
              "      <td>SF</td>\n",
              "      <td>25.0</td>\n",
              "      <td>6-6</td>\n",
              "      <td>235.0</td>\n",
              "      <td>Marquette</td>\n",
              "      <td>6796117.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>John Holland</td>\n",
              "      <td>Boston Celtics</td>\n",
              "      <td>30.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6-5</td>\n",
              "      <td>205.0</td>\n",
              "      <td>Boston University</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>R.J. Hunter</td>\n",
              "      <td>Boston Celtics</td>\n",
              "      <td>28.0</td>\n",
              "      <td>SG</td>\n",
              "      <td>22.0</td>\n",
              "      <td>6-5</td>\n",
              "      <td>185.0</td>\n",
              "      <td>Georgia State</td>\n",
              "      <td>1148640.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jonas Jerebko</td>\n",
              "      <td>Boston Celtics</td>\n",
              "      <td>8.0</td>\n",
              "      <td>PF</td>\n",
              "      <td>29.0</td>\n",
              "      <td>6-10</td>\n",
              "      <td>231.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>Shelvin Mack</td>\n",
              "      <td>Utah Jazz</td>\n",
              "      <td>8.0</td>\n",
              "      <td>PG</td>\n",
              "      <td>26.0</td>\n",
              "      <td>6-3</td>\n",
              "      <td>203.0</td>\n",
              "      <td>Butler</td>\n",
              "      <td>2433333.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>Raul Neto</td>\n",
              "      <td>Utah Jazz</td>\n",
              "      <td>25.0</td>\n",
              "      <td>PG</td>\n",
              "      <td>24.0</td>\n",
              "      <td>6-1</td>\n",
              "      <td>179.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>900000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>Tibor Pleiss</td>\n",
              "      <td>Utah Jazz</td>\n",
              "      <td>21.0</td>\n",
              "      <td>C</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7-3</td>\n",
              "      <td>256.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2900000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>Jeff Withey</td>\n",
              "      <td>Utah Jazz</td>\n",
              "      <td>24.0</td>\n",
              "      <td>C</td>\n",
              "      <td>26.0</td>\n",
              "      <td>7-0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>Kansas</td>\n",
              "      <td>947276.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>458 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Name            Team  Number Position   Age Height  Weight  \\\n",
              "0    Avery Bradley  Boston Celtics     0.0       PG  25.0    6-2   180.0   \n",
              "1      Jae Crowder  Boston Celtics    99.0       SF  25.0    6-6   235.0   \n",
              "2     John Holland  Boston Celtics    30.0       SG  27.0    6-5   205.0   \n",
              "3      R.J. Hunter  Boston Celtics    28.0       SG  22.0    6-5   185.0   \n",
              "4    Jonas Jerebko  Boston Celtics     8.0       PF  29.0   6-10   231.0   \n",
              "..             ...             ...     ...      ...   ...    ...     ...   \n",
              "453   Shelvin Mack       Utah Jazz     8.0       PG  26.0    6-3   203.0   \n",
              "454      Raul Neto       Utah Jazz    25.0       PG  24.0    6-1   179.0   \n",
              "455   Tibor Pleiss       Utah Jazz    21.0        C  26.0    7-3   256.0   \n",
              "456    Jeff Withey       Utah Jazz    24.0        C  26.0    7-0   231.0   \n",
              "457            NaN             NaN     NaN      NaN   NaN    NaN     NaN   \n",
              "\n",
              "               College     Salary  \n",
              "0                Texas  7730337.0  \n",
              "1            Marquette  6796117.0  \n",
              "2    Boston University        NaN  \n",
              "3        Georgia State  1148640.0  \n",
              "4                  NaN  5000000.0  \n",
              "..                 ...        ...  \n",
              "453             Butler  2433333.0  \n",
              "454                NaN   900000.0  \n",
              "455                NaN  2900000.0  \n",
              "456             Kansas   947276.0  \n",
              "457                NaN        NaN  \n",
              "\n",
              "[458 rows x 9 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge 2\n",
        "# Use the lstrip() function of .str method to check the variables with the leading and trailing spaces.\n",
        "# of the given NBA dataset below. \n",
        "# Later, strip those leading and trailing spaces in the identified variables.\n",
        "url = 'http://bit.ly/MSDS-NBADataset'\n",
        "# \n",
        "df = pd.read_csv(url)\n",
        "df\n",
        "df['Name'] = df['Name'].str.lstrip()\n",
        "df\n",
        "df['Team']= df['Team'].str.lstrip()\n",
        "df\n",
        "df['College']= df['College'].str.lstrip()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "YOohec0jHL4-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MARCHE~1\\AppData\\Local\\Temp/ipykernel_11284/2491650593.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['Alabama[edit]'] = df['Alabama[edit]'].str.replace('[edit]','')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Alabama[edit]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Auburn (Auburn Unvrsy)[1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Flornc (Unvrsy of Norh Alabama)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jacksonvll (Jacksonvll Sa Unvrsy)[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lvngson (Unvrsy of Ws Alabama)[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Monvallo (Unvrsy of Monvallo)[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>Svns Pon (Unvrsy of Wsconsn–Svns Pon)[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>Wauksha (Carroll Unvrsy)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>Whwar (Unvrsy of Wsconsn–Whwar)[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>Wyomng[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>Laram (Unvrsy of Wyomng)[5]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>566 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                Alabama[edit]\n",
              "0                   Auburn (Auburn Unvrsy)[1]\n",
              "1             Flornc (Unvrsy of Norh Alabama)\n",
              "2        Jacksonvll (Jacksonvll Sa Unvrsy)[2]\n",
              "3           Lvngson (Unvrsy of Ws Alabama)[2]\n",
              "4            Monvallo (Unvrsy of Monvallo)[2]\n",
              "..                                        ...\n",
              "561  Svns Pon (Unvrsy of Wsconsn–Svns Pon)[2]\n",
              "562                  Wauksha (Carroll Unvrsy)\n",
              "563        Whwar (Unvrsy of Wsconsn–Whwar)[2]\n",
              "564                                  Wyomng[]\n",
              "565               Laram (Unvrsy of Wyomng)[5]\n",
              "\n",
              "[566 rows x 1 columns]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge 3\n",
        "# Remove the text [edit] at the end of the university towns use sing the replace() function of the .str method\n",
        "# Use the following dataset; \n",
        "url = 'http://bit.ly/MSUniversityTown'\n",
        "#\n",
        "df = pd.read_csv(url, delimiter=';')\n",
        "df\n",
        "df['Alabama[edit]'] = df['Alabama[edit]'].str.replace('[edit]','')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxpZyP9yxlzl"
      },
      "source": [
        "## 1.2 Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ8DPOj4HGtQ"
      },
      "source": [
        "### <font color=\"green\">1.2 Challenge</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "zLGcCGXDxoKE"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Urban_Center</th>\n",
              "      <th>District</th>\n",
              "      <th>Status</th>\n",
              "      <th>Core-Urban_Male_Population</th>\n",
              "      <th>Core-Urban_Female_Population</th>\n",
              "      <th>Total_Core-Urban_Population</th>\n",
              "      <th>Peri-Urban_Male_Population</th>\n",
              "      <th>Peri-Urban_Female_Population</th>\n",
              "      <th>Total_Peri-Urban_Population</th>\n",
              "      <th>Rural_Male_Population</th>\n",
              "      <th>Rural_Female_Population</th>\n",
              "      <th>Total_Rural_Population</th>\n",
              "      <th>Total_Male_Population</th>\n",
              "      <th>Total_Female_Population</th>\n",
              "      <th>Total_Population</th>\n",
              "      <th>OBJECTID</th>\n",
              "      <th>Newtotal</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Urban_Center, District, Status, Core-Urban_Male_Population, Core-Urban_Female_Population, Total_Core-Urban_Population, Peri-Urban_Male_Population, Peri-Urban_Female_Population, Total_Peri-Urban_Population, Rural_Male_Population, Rural_Female_Population, Total_Rural_Population, Total_Male_Population, Total_Female_Population, Total_Population, OBJECTID, Newtotal, diff]\n",
              "Index: []"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge 1: In-record & cross-datasets errors\n",
        "# These errors result from having two or more values in the same row or across \n",
        "# datasets that contradict with each other. \n",
        "# For example, if we have a dataset about the cost of living in cities. \n",
        "# The total column must be equivalent to the sum of rent, transport, and food. \n",
        "# Similarly, a child can’t be married. An employee’s salary can’t be less than the calculated taxes etc.\n",
        "# Using the given dataset below, determine and fix errors where the total population is not a sum of\n",
        "# total male population and total female population \n",
        "# dataset \n",
        "# Hint: Review Pandas Basics \n",
        "# \n",
        "url = 'http://bit.ly/MSPopulationDistribution'\n",
        "df = pd.read_csv(url)\n",
        "df\n",
        "df['Newtotal'] = df['Total_Male_Population'] + df['Total_Female_Population']\n",
        "df\n",
        "import numpy as np\n",
        "df['diff'] = np.where(df['Total_Population']==df['Newtotal'],'T','F')\n",
        "df[df['diff']=='F']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPXKeupMxvT3"
      },
      "source": [
        "## 1.3 Completeness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "lmS8QbRnxy5m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science    NaN\n",
            "3         Mathematics   74.0\n",
            "4             Physics    NaN\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n",
            "True\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Checking/ Counting Missing Values \n",
        "# \n",
        "\n",
        "# Creating a dataframe to work with\n",
        "df1 = {\n",
        "    'Subject':['Humanities', 'Physical Education', 'Home Science', 'Mathematics', 'Physics',\n",
        "               'Chemistry','Arts'],\n",
        "   'Score':[62, 47, np.nan, 74, np.nan, 77, 85]}\n",
        " \n",
        "df1 = pd.DataFrame(df1,columns=['Subject','Score'])\n",
        "\n",
        "print(df1)\n",
        "\n",
        "# Checking if there is any missing value in dataframe as a whole\n",
        "# Uncomment the following line after running the previous lines\n",
        "df1.isnull()\n",
        "\n",
        "# Checking if there is any missing value across each column\n",
        "# Uncomment the following line after running the previous lines\n",
        "df1.isnull().any()\n",
        "\n",
        "# Checking how many missing values there are across each column\n",
        "# Uncomment the following line after running the previous lines\n",
        "df1.isnull().sum()\n",
        "\n",
        "# Or we can do a quick check to see if we have any missing values at all\n",
        "# Uncomment the following line after running the previous lines\n",
        "print(df1.isnull().values.any())\n",
        "\n",
        "# We might also want to get a total count of missing values\n",
        "# Uncomment the following line after running the previous lines\n",
        "print(df1.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "zGDJy7rYiZOt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "3         Mathematics   74.0\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n",
            "Subject    0\n",
            "Score      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Dropping Missing Values \n",
        "# If there are only a few null values and you know that deleting values \n",
        "# will not cause adverse effects on your result, \n",
        "# remove them from your DataFrame and store that in a new DataFrame\n",
        "\n",
        "# Droppping all \n",
        "# Uncomment the following 2 lines after running the previous lines\n",
        "clean_df = df1.dropna()\n",
        "print(clean_df)\n",
        "\n",
        "# Verifying that you no longer have any null values by running \n",
        "# Uncomment the following line after running the previous lines\n",
        "print(clean_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Vg0NXacDkkb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "3         Mathematics   74.0\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n",
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science    NaN\n",
            "3         Mathematics   74.0\n",
            "4             Physics    NaN\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n",
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "3         Mathematics   74.0\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n"
          ]
        }
      ],
      "source": [
        "# Exmaple 2: Dropping instances/records/rows with NA missing values \n",
        "# \n",
        "\n",
        "# Dropping all rows with any NA values \n",
        "all_rows_any_na = df1.dropna()\n",
        "print(all_rows_any_na)\n",
        "\n",
        "# Dropping all rows that have all NA values\n",
        "# Uncomment the 2 lines below after running the previous lines\n",
        "all_rows_all_na = df1.dropna(how=\"all\")\n",
        "print(all_rows_all_na)\n",
        "\n",
        "# We can also put a limitation on how many non-null values need to be in a row \n",
        "# we can retain the data that has at least 2 non-null values as shown below\n",
        "# Uncomment the 2 lines below after running the previous lines\n",
        "df1_thresh = df1.dropna(thresh=2)\n",
        "print(df1_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "nci4gXJb1u21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Subject\n",
            "0          Humanities\n",
            "1  Physical Education\n",
            "2        Home Science\n",
            "3         Mathematics\n",
            "4             Physics\n",
            "5           Chemistry\n",
            "6                Arts\n",
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science    NaN\n",
            "3         Mathematics   74.0\n",
            "4             Physics    NaN\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n",
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "3         Mathematics   74.0\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Missing Values\n",
        "# Dropping attributes (variables/columns)\n",
        "# We can apply the same kind of criteria to our columns. \n",
        "# We just need to use the parameter axis=1 in our code. \n",
        "# That means to operate on columns, not rows. \n",
        "# (We could have used axis=0 in our row examples, \n",
        "# but it is 0 by default if you don’t enter anything.)\n",
        "# \n",
        "\n",
        "# Dropping all attributes with any NA values\n",
        "# \n",
        "all_cols_any_na = df1.dropna(axis=1)\n",
        "print(all_cols_any_na)\n",
        "\n",
        "# Dropping all attributes that have all NA values\n",
        "# Uncomment the 2 lines below\n",
        "\n",
        "all_cols_all_na = df1.dropna(axis=1, how=\"all\")\n",
        "print(all_cols_all_na)\n",
        "\n",
        "# We can also put a limitation on how many non-null values need to be in a attributes \n",
        "# we can retain the data that has at least 2 non-null values as shown below\n",
        "# Uncomment the 2 lines below\n",
        "df1_thresh = df1.dropna(thresh=2)\n",
        "print(df1_thresh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "UHD7y5ti10Am"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science    NaN\n",
            "3         Mathematics   74.0\n",
            "4             Physics    NaN\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n",
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science   69.0\n",
            "3         Mathematics   74.0\n",
            "4             Physics   69.0\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n"
          ]
        }
      ],
      "source": [
        "# Example 3: Missing Values\n",
        "# Imputing the attribute mean for all missing values\n",
        "# Mean imputation replaces missing values with the mean value of that feature/variable. \n",
        "# Mean imputation is one of the most ‘naive’ imputation methods \n",
        "# because unlike more complex methods like k-nearest neighbors imputation, \n",
        "# it does not use the information we have about an observation to estimate a value for it.\n",
        "\n",
        "# Creating a dataframe to work with\n",
        "subjects_df_mean = {\n",
        "    'Subject':['Humanities', 'Physical Education', 'Home Science', 'Mathematics', 'Physics',\n",
        "               'Chemistry','Arts'],\n",
        "   'Score':[62, 47, np.nan, 74, np.nan, 77, 85]}\n",
        "subjects_df_mean = pd.DataFrame(subjects_df_mean,columns=['Subject','Score'])\n",
        "\n",
        "# printing our dataframe\n",
        "print(subjects_df_mean)\n",
        "\n",
        "# # imputing the mean \n",
        "subjects_df_mean['Score'] = subjects_df_mean['Score'].fillna((subjects_df_mean['Score'].mean()))\n",
        "\n",
        "# # printing out our updated dataframe\n",
        "print(subjects_df_mean) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Xk9aj32K15B1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science    NaN\n",
            "3         Mathematics   74.0\n",
            "4             Physics    NaN\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n",
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science   74.0\n",
            "3         Mathematics   74.0\n",
            "4             Physics   74.0\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n"
          ]
        }
      ],
      "source": [
        "# Example 4: Missing Values\n",
        "# Imputing the attribute median for all missing values\n",
        "# \n",
        "\n",
        "# Creating a dataframe to work with\n",
        "subjects_df_median = {\n",
        "    'Subject':['Humanities', 'Physical Education', 'Home Science', 'Mathematics', 'Physics',\n",
        "               'Chemistry','Arts'],\n",
        "   'Score':[62, 47, np.nan, 74, np.nan, 77, 85]}\n",
        "subjects_df_median = pd.DataFrame(subjects_df_median,columns=['Subject','Score'])\n",
        "\n",
        "# printing our dataframe\n",
        "print(subjects_df_median)\n",
        "\n",
        "#imputing the median \n",
        "subjects_df_median['Score'] = subjects_df_median['Score'].fillna((subjects_df_median['Score'].median()))\n",
        "\n",
        "# printing out our updated dataframe\n",
        "print(subjects_df_median) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Fiz_Fl_u1_oh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science    NaN\n",
            "3         Mathematics   74.0\n",
            "4             Physics    NaN\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n",
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science   74.0\n",
            "3         Mathematics   74.0\n",
            "4             Physics   85.0\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n"
          ]
        }
      ],
      "source": [
        "# Example 5: Missing Values \n",
        "# Imputing the attribute mode for all missing values\n",
        "# \n",
        "# Creating a dataframe to work with\n",
        "subjects_df_mode = {\n",
        "    'Subject':['Humanities', 'Physical Education', 'Home Science', 'Mathematics', 'Physics',\n",
        "               'Chemistry','Arts'],\n",
        "   'Score':[62, 47, np.nan, 74, np.nan, 77, 85]}\n",
        "subjects_df_mode = pd.DataFrame(subjects_df_mode,columns=['Subject','Score'])\n",
        "\n",
        "# printing our dataframe\n",
        "print(subjects_df_mode)\n",
        "\n",
        "# imputing the mode \n",
        "subjects_df_mode['Score'] = subjects_df_mode['Score'].fillna((subjects_df_mode['Score'].mode()))\n",
        "\n",
        "# printing out our updated dataframe\n",
        "print(subjects_df_mode) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "uEpXn0qbP-Fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              Subject  Score\n",
            "0          Humanities   62.0\n",
            "1  Physical Education   47.0\n",
            "2        Home Science   60.0\n",
            "3         Mathematics   74.0\n",
            "4             Physics   60.0\n",
            "5           Chemistry   77.0\n",
            "6                Arts   85.0\n"
          ]
        }
      ],
      "source": [
        "# Example 6: Missing Values \n",
        "# Or maybe we just want to fill in missing values with a single value as shown below\n",
        "# \n",
        "\n",
        "df1 = {\n",
        "    'Subject':['Humanities', 'Physical Education', 'Home Science', 'Mathematics', 'Physics',\n",
        "               'Chemistry','Arts'],\n",
        "   'Score':[62, 47, np.nan, 74, np.nan, 77, 85]}\n",
        " \n",
        "df1 = pd.DataFrame(df1,columns=['Subject','Score'])\n",
        "\n",
        "# Replace missing values with a number\n",
        "df1['Score'].fillna(60, inplace=True)\n",
        "\n",
        "print(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "JDIwtGtHSb48"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PID</th>\n",
              "      <th>ST_NUM</th>\n",
              "      <th>ST_NAME</th>\n",
              "      <th>OWN_OCCUPIED</th>\n",
              "      <th>NUM_BEDROOMS</th>\n",
              "      <th>NUM_BATH</th>\n",
              "      <th>SQ_FT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100001000.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>PUTNAM</td>\n",
              "      <td>Y</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100002000.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>LEXINGTON</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>--</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100003000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LEXINGTON</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100004000.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>BERKELEY</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>203.0</td>\n",
              "      <td>BERKELEY</td>\n",
              "      <td>Y</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>100006000.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>BERKELEY</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100007000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WASHINGTON</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>HURLEY</td>\n",
              "      <td>950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>100008000.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>TREMONT</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>100009000.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>TREMONT</td>\n",
              "      <td>Y</td>\n",
              "      <td>na</td>\n",
              "      <td>2</td>\n",
              "      <td>1800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           PID  ST_NUM     ST_NAME OWN_OCCUPIED NUM_BEDROOMS NUM_BATH SQ_FT\n",
              "0  100001000.0   104.0      PUTNAM            Y            3        1  1000\n",
              "1  100002000.0   197.0   LEXINGTON            N            3      1.5    --\n",
              "2  100003000.0     NaN   LEXINGTON            N          NaN        1   850\n",
              "3  100004000.0   201.0    BERKELEY           12            1      NaN   700\n",
              "4          NaN   203.0    BERKELEY            Y            3        2  1600\n",
              "5  100006000.0   207.0    BERKELEY            Y          NaN        1   800\n",
              "6  100007000.0     NaN  WASHINGTON          NaN            2   HURLEY   950\n",
              "7  100008000.0   213.0     TREMONT            Y            1        1   NaN\n",
              "8  100009000.0   215.0     TREMONT            Y           na        2  1800"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 7: Missing Values\n",
        "# Using the following property dataset, we will make a list of missing value types\n",
        "# then load our dataset below\n",
        "# \n",
        "\n",
        "# reading our dataset\n",
        "property_dataset = pd.read_csv(\"http://bit.ly/MS-PropertyDataset\")\n",
        "property_dataset\n",
        "\n",
        "# Now making a list of missing value types found in our dataset\n",
        "# Uncommenting the 3 lines below after running the previous lines\n",
        "#missing_values = [\"n/a\", \"na\", \"--\"]\n",
        "# property_dataset = pd.read_csv(\"http://bit.ly/MS-PropertyDataset\", na_values = missing_values)\n",
        "# property_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSSnxqGcH4pc"
      },
      "source": [
        "### <font color=\"green\">1.3 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "YIeuI-bXH9ZX"
      },
      "outputs": [],
      "source": [
        "# Challenge 1\n",
        "# Clean the following dataset that contains missing values\n",
        "url = 'http://bit.ly/DSRussianInvestigation'\n",
        "# \n",
        "missing_values = [\"NaT\",\"n/a\", \"na\", \"--\"]\n",
        "df = pd.read_csv(url,na_values=missing_values)\n",
        "df.isnull().sum()\n",
        "df['investigation-start'] = pd.to_datetime(df['investigation-start'])\n",
        "df['investigation-end'] = pd.to_datetime(df['investigation-end'])\n",
        "df['investigation-days'] = pd.to_timedelta(df['investigation-days'])\n",
        "\n",
        "df['investigation-end'] = df['investigation-end'].fillna(df['investigation-start'] + df['investigation-days'])\n",
        "\n",
        "df['name'] = df['name'].fillna('Unknown')\n",
        "df['indictment-days '] = df['indictment-days '].fillna(method='ffill')\n",
        "df['type'] = df['type'].fillna(method='ffill')\n",
        "\n",
        "# df\n",
        "# df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "eErv30zQH-gS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "URL                            0\n",
              "Name/Alias                     0\n",
              "Appearances                    0\n",
              "Current?                       0\n",
              "Gender                         0\n",
              "Full/Reserve Avengers Intro    0\n",
              "Year                           0\n",
              "Years since joining            0\n",
              "Honorary                       0\n",
              "Death1                         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge 2\n",
        "# Examine and clean the avengers dataset\n",
        "# http://bit.ly/MSAvengers\n",
        "# \n",
        "df = pd.read_csv(\"http://bit.ly/MSAvengers\", encoding='ISO8859')\n",
        "\n",
        "df.drop(columns=['Probationary Introl','Return1','Death2','Return2','Death3','Return3','Death4','Return4','Death5','Return5','Notes'],inplace = True)\n",
        "\n",
        "df['Name/Alias'].fillna('Unknown',inplace = True)\n",
        "df['Full/Reserve Avengers Intro'].fillna(method='bfill',inplace = True)\n",
        "df.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "RMR09nkWH_vH"
      },
      "outputs": [],
      "source": [
        "# Challenge 3\n",
        "# Clean the dataset where 16 multiple choice ability items were taken from the Synthetic Aperture Personality Assessment (SAPA)\n",
        "# web based personality assessment project. The data from 1525 subjects are included as a demonstration \n",
        "# set for scoring multiple choice inventories and doing basic item statistics.\n",
        "# url = 'http://bit.ly/MSIQQuestions'\n",
        "# #\n",
        "# df= pd.read_csv(url)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "cxSSVFTGRbrq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Row</th>\n",
              "      <th>Col</th>\n",
              "      <th>Hgt90</th>\n",
              "      <th>Hgt96</th>\n",
              "      <th>Diam96</th>\n",
              "      <th>Grow96</th>\n",
              "      <th>Hgt97</th>\n",
              "      <th>Diam97</th>\n",
              "      <th>Spread.97</th>\n",
              "      <th>Needles97</th>\n",
              "      <th>Deer95</th>\n",
              "      <th>Deer97</th>\n",
              "      <th>Cover95</th>\n",
              "      <th>Fert</th>\n",
              "      <th>Spacing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>14.0</td>\n",
              "      <td>284.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>96.0</td>\n",
              "      <td>362.0</td>\n",
              "      <td>6.6</td>\n",
              "      <td>162.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>17.0</td>\n",
              "      <td>387.0</td>\n",
              "      <td>7.4</td>\n",
              "      <td>110.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>9.3</td>\n",
              "      <td>250.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>24.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>70.0</td>\n",
              "      <td>369.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>22.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>84.0</td>\n",
              "      <td>365.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>215.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>318.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>96.0</td>\n",
              "      <td>356.0</td>\n",
              "      <td>7.6</td>\n",
              "      <td>238.0</td>\n",
              "      <td>74.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>994</th>\n",
              "      <td>995</td>\n",
              "      <td>44</td>\n",
              "      <td>22</td>\n",
              "      <td>21.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>71.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>116.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>996</td>\n",
              "      <td>44</td>\n",
              "      <td>23</td>\n",
              "      <td>17.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>4.6</td>\n",
              "      <td>100.0</td>\n",
              "      <td>448.0</td>\n",
              "      <td>6.4</td>\n",
              "      <td>229.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>997</td>\n",
              "      <td>44</td>\n",
              "      <td>24</td>\n",
              "      <td>20.0</td>\n",
              "      <td>315.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>81.0</td>\n",
              "      <td>388.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>998</td>\n",
              "      <td>44</td>\n",
              "      <td>25</td>\n",
              "      <td>11.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>4.2</td>\n",
              "      <td>91.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>7.2</td>\n",
              "      <td>241.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>999</td>\n",
              "      <td>44</td>\n",
              "      <td>26</td>\n",
              "      <td>19.0</td>\n",
              "      <td>231.0</td>\n",
              "      <td>2.4</td>\n",
              "      <td>76.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>127.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>778 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  Row  Col  Hgt90  Hgt96  Diam96  Grow96  Hgt97  Diam97  \\\n",
              "1             2    1    2   14.0  284.0     4.2    96.0  362.0     6.6   \n",
              "2             3    1    3   17.0  387.0     7.4   110.0  442.0     9.3   \n",
              "4             5    1    5   24.0  294.0     3.9    70.0  369.0     7.0   \n",
              "5             6    1    6   22.0  310.0     5.6    84.0  365.0     6.9   \n",
              "6             7    1    7   18.0  318.0     5.4    96.0  356.0     7.6   \n",
              "..          ...  ...  ...    ...    ...     ...     ...    ...     ...   \n",
              "994         995   44   22   21.0  213.0     2.3    71.0  287.0     3.7   \n",
              "995         996   44   23   17.0  346.0     4.6   100.0  448.0     6.4   \n",
              "996         997   44   24   20.0  315.0     4.3    81.0  388.0     7.0   \n",
              "997         998   44   25   11.0  319.0     4.2    91.0  381.0     7.2   \n",
              "998         999   44   26   19.0  231.0     2.4    76.0  263.0     4.9   \n",
              "\n",
              "     Spread.97  Needles97  Deer95  Deer97  Cover95  Fert  Spacing  \n",
              "1        162.0       66.0     0.0     1.0        2     0       15  \n",
              "2        250.0       77.0     0.0     0.0        1     0       15  \n",
              "4        176.0       72.0     0.0     0.0        2     0       15  \n",
              "5        215.0       76.0     0.0     0.0        1     0       15  \n",
              "6        238.0       74.5     0.0     0.0        0     0       15  \n",
              "..         ...        ...     ...     ...      ...   ...      ...  \n",
              "994      116.0       65.0     0.0     1.0        0     0       10  \n",
              "995      229.0       85.0     1.0     1.0        1     0       10  \n",
              "996      206.0       63.0     1.0     1.0        1     0       10  \n",
              "997      241.0       63.0     1.0     1.0        0     0       10  \n",
              "998      127.0       63.0     1.0     1.0        0     0       10  \n",
              "\n",
              "[778 rows x 16 columns]"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge 4\n",
        "# The dataset below contains data from an experiment conducted by the Department of Biology \n",
        "# at Kenyon College at a site near the campus in Gambier, Ohio. A student and faculty volunteers \n",
        "# planted 1000 white pine (Pinus strobes) seedlings at the Brown Family Environmental Center. \n",
        "# These seedlings were planted in two grids, distinguished by 10- and 15-foot spacings between the seedlings. \n",
        "# Several variables were measured and recorded for each seedling over time (in 1990, 1996, and 1997).\n",
        "# Handle the missing values of this dataset; dataset url = http://bit.ly/MSPines\n",
        "df = pd.read_csv('http://bit.ly/MSPines')\n",
        "df\n",
        "# Features Description\n",
        "# Row\tRow number in pine plantation\n",
        "# Col\tColumn number in pine plantation\n",
        "# Hgt90\tTree height at time of planting (cm)\n",
        "# Hgt96\tTree height in September 1996 (cm)\n",
        "# Diam96\tTree trunk diameter in September 1996 (cm)\n",
        "# Grow96\tLeader growth during 1996 (cm)\n",
        "# Hgt97\tTree height in September 1997 (cm)\n",
        "# Diam97\tTree trunk diameter in September 1997 (cm)\n",
        "# Spread97\tWidest lateral spread in September 1997 (cm)\n",
        "# Needles97\tNeedle length in September 1997 (mm)\n",
        "# Deer95\tType of deer damage in September 1995: 0 = none, 1 = browsed\n",
        "# Deer97\tType of deer damage in September 1997: 0 = none, 1 = browsed\n",
        "# Cover95\tThorny cover in September 1995: 0 = none; 1 = some; 2 = moderate; 3 = lots\n",
        "# Fert\tIndicator for fertilizer: 0 = no, 1 = yes\n",
        "# Spacing\tDistance (in feet) between trees (10 or 15)\n",
        "#\n",
        "df.dropna(inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "12QcGkaPUEVN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "River         0\n",
              "Site          0\n",
              "Al            0\n",
              "Ba            0\n",
              "Br            0\n",
              "Ca            0\n",
              "Ce            0\n",
              "Cu            0\n",
              "Dy            0\n",
              "Er            0\n",
              "Fe            0\n",
              "Gd            0\n",
              "Ho            0\n",
              "K             0\n",
              "La            0\n",
              "Li            0\n",
              "Mg            0\n",
              "Mn            0\n",
              "Nd            0\n",
              "Pr            0\n",
              "Rb            0\n",
              "Si            0\n",
              "Sr            0\n",
              "Y             0\n",
              "Yb            0\n",
              "Zn            0\n",
              "Zr            0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 148,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge 5\n",
        "# Some geologists were interested in the water chemistry of rivers in Coastal New York. \n",
        "# They took water samples at three different locations in four rivers. \n",
        "# The sampling sites were chosen to investigate how the composition of the water changes \n",
        "# as it flows from the source to the mouth of each river. \n",
        "# The sampling sites were labeled as upstream, midstream, and downstream. \n",
        "# This dataset contains the concentrations (parts per million) of a variety of elements in those water samples. \n",
        "# The dataset RiverIron contains the information for iron (FE) alone, along with the log of the concentration.\n",
        "# Handle the missing values found in this dataset; dataset url = http://bit.ly/MSRiverSamples\n",
        "df = pd.read_csv('http://bit.ly/MSRiverSamples')\n",
        "df\n",
        "# Features Description\n",
        "# River\tOne of four rivers: Grasse, Oswegatchie, Raquette, or St. Regis\n",
        "# Site\tLocation: 1=UpStream, 2=MidStream, 3=Downstream\n",
        "# Al\tAluminum\n",
        "# Ba\tBarium\n",
        "# Br\tBromine\n",
        "# Ca\tCalcium\n",
        "# Ce\tCerium\n",
        "# Cu\tCopper\n",
        "# Dy\tDysprosium\n",
        "# Er\tErbim\n",
        "# Fe\tIron\n",
        "# Gd\tGadolinium\n",
        "# Ho\tHolmum\n",
        "# K\tPotassium\n",
        "# La\tLathanum\n",
        "# Li\tLithium\n",
        "# Mg\tMagnesium\n",
        "# Mn\tManganese\n",
        "# Nd\tNeodymium\n",
        "# Pr\tProseyodymium\n",
        "# Rb\tRubidium\n",
        "# Si\tSilicon\n",
        "# Sr\tStrontium\n",
        "# Y\tYttrium\n",
        "# Yb\tYtterbium\n",
        "# Zn\tZinc\n",
        "# Zr\tZirconium\n",
        "#\n",
        "df['Ho'] = df['Ho'].fillna(df['Ho'].mean())\n",
        "df['Ho']\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wus-RyPhx2k2"
      },
      "source": [
        "## 1.4 Consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EhBEUGcTx78K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  first_name   last_name  age  pre_assessment  post_assessment\n",
            "0     Jamila    Mohammed   52               5               35\n",
            "1     Jamila    Mohammed   52               5               35\n",
            "2       Jane      Milner   43               5               25\n",
            "3       Joma        Tech   77              43               57\n",
            "4       Ulia  Shevchenko   25               5               72\n",
            "5     Dorcas     Wanjiru   19               2               71\n",
            "  first_name   last_name  age  pre_assessment  post_assessment\n",
            "0     Jamila    Mohammed   52               5               35\n",
            "2       Jane      Milner   43               5               25\n",
            "3       Joma        Tech   77              43               57\n",
            "4       Ulia  Shevchenko   25               5               72\n",
            "5     Dorcas     Wanjiru   19               2               71\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Duplicates\n",
        "# Duplicates are data points that are repeated in your dataset. \n",
        "# These should be simply removed.\n",
        "#\n",
        "import pandas as pd\n",
        "raw_data = {'first_name': ['Jamila', 'Jamila', 'Jane','Joma', 'Ulia', 'Dorcas'], \n",
        "        'last_name': ['Mohammed', 'Mohammed', 'Milner','Tech', 'Shevchenko', 'Wanjiru'], \n",
        "        'age': [52, 52, 43, 77, 25, 19], \n",
        "        'pre_assessment': [5, 5, 5, 43, 5, 2],\n",
        "        'post_assessment': [35, 35, 25, 57, 72, 71]}\n",
        "df_duplicate = pd.DataFrame(raw_data, columns = ['first_name', 'last_name', 'age', 'pre_assessment', 'post_assessment'])\n",
        "print(df_duplicate)\n",
        "\n",
        "\n",
        "# Identifying which observations are duplicates\n",
        "df_non_duplicates = df_duplicate.drop_duplicates()\n",
        "\n",
        "# Let's see these non-duplicate files\n",
        "print(df_non_duplicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvxGZOoWXnmy"
      },
      "source": [
        "### <font color=\"green\">1.4 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "grvCd8d0XuCC"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     False\n",
              "1     False\n",
              "2     False\n",
              "3     False\n",
              "4     False\n",
              "5     False\n",
              "6     False\n",
              "7     False\n",
              "8     False\n",
              "9     False\n",
              "10    False\n",
              "11    False\n",
              "12    False\n",
              "13    False\n",
              "dtype: bool"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge  1\n",
        "# Identify and handle the duplicted records found in the following dataset\n",
        "# dataset url = http://bit.ly/MoviesDataset1\n",
        "# \n",
        "data = pd.read_csv(\"http://bit.ly/MoviesDataset1\")\n",
        "data\n",
        "data.duplicated()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MQ0BKjhPXyhP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Clean the following dataset \n",
        "# dataset url = http://bit.ly/EmployeesDataset\n",
        "# \n",
        "data = pd.read_csv(\"http://bit.ly/EmployeesDataset\")\n",
        "data\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o59W2bFhx_8k"
      },
      "source": [
        "## 1.5 Uniformity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EnpBH69HTLWe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Moderator        Date  Score\n",
            "0   Wanjiku  2015-02-11     14\n",
            "1   Muthoni  2013-02-22     34\n",
            "2    Kagure  2015-02-11     41\n",
            "3     Muema  2014-02-11     12\n",
            "4   Kariuki  2011-02-11     13\n",
            "  Senior Leader        Time  Score\n",
            "0       Wanjiku  2015-02-11     14\n",
            "1       Muthoni  2013-02-22     34\n",
            "2        Kagure  2015-02-11     41\n",
            "3         Muema  2014-02-11     12\n",
            "4       Kariuki  2011-02-11     13\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Standardization - Renaming column names\n",
        "# We can rename multiple  data frame column names in the following manner\n",
        "# \n",
        "\n",
        "# Create an example dataframe\n",
        "#\n",
        "officials_data = {'Moderator': ['Wanjiku', 'Muthoni', 'Kagure', 'Muema', 'Kariuki'], \n",
        "        'Date': ['2015-02-11', '2013-02-22', '2015-02-11', '2014-02-11', '2011-02-11'], \n",
        "        'Score': [14, 34, 41, 12, 13]}\n",
        "officials_data = pd.DataFrame(officials_data)\n",
        "print(officials_data)\n",
        "\n",
        "# Renaming the column names\n",
        "#\n",
        "officials_data.columns = ['Senior Leader', 'Time', 'Score']\n",
        "print(officials_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_wOLNaUFUy72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  senior_leader        time  score\n",
            "0       Wanjiku  2015-02-11     14\n",
            "1       Muthoni  2013-02-22     34\n",
            "2        Kagure  2015-02-11     41\n",
            "3         Muema  2014-02-11     12\n",
            "4       Kariuki  2011-02-11     13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MARCHE~1\\AppData\\Local\\Temp/ipykernel_2300/3694656004.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  officials_data.columns = officials_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Standardization - Fixing messy column names\n",
        "# Sometimes you might have column names which are uppercase, with spaces, \n",
        "# and whitespace all around. How do we fix this? \n",
        "# We use the .str method that we use on text data. \n",
        "# Ideally, we chain a bunch of .str functions as shown below; \n",
        "# \n",
        "\n",
        "# we use strip(), lower() and replace() functions\n",
        "# \n",
        "officials_data.columns = officials_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
        "print(officials_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "npCCbSYHyLJu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   date    10 non-null     object\n",
            " 1   value   10 non-null     int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 288.0+ bytes\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   date    10 non-null     datetime64[ns]\n",
            " 1   value   10 non-null     int64         \n",
            "dtypes: datetime64[ns](1), int64(1)\n",
            "memory usage: 288.0 bytes\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Example 3: Date Type Conversion\n",
        "# Make sure numbers are stored as numerical data types. \n",
        "# A date should be stored as a date object, or a Unix timestamp (number of seconds), and so on. \n",
        "# Making the respecive conversion is advised.\n",
        "# \n",
        "\n",
        "# Let's convert our strings to Datetime data type\n",
        "# importing datatime module\n",
        "from datetime import datetime\n",
        "\n",
        "# Creating our data frame\n",
        "data = {'date': ['2015-05-01 18:47:05.069722', '2015-05-01 18:47:05.119994', \n",
        "                 '2015-05-02 18:47:05.178768', '2015-05-02 18:47:05.230071', \n",
        "                 '2015-05-02 18:47:05.230071', '2015-05-02 18:47:05.280592', \n",
        "                 '2015-05-03 18:47:05.332662', '2015-05-03 18:47:05.385109', \n",
        "                 '2015-05-04 18:47:05.436523', '2015-05-04 18:47:05.486877'], \n",
        "        'value': [1, 2, 4, 5, 6, 3, 2, 1, 15, 11]}\n",
        "df = pd.DataFrame(data, columns = ['date', 'value'])\n",
        "\n",
        "# printing our dataframe\n",
        "print(df.info())\n",
        "\n",
        "# Converting date column from string to datetime\n",
        "df['date'] = pd.to_datetime(df['date']) \n",
        "\n",
        "# printing our updated dataframe\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6vJvDVMWKanz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5043 entries, 0 to 5042\n",
            "Data columns (total 28 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   color                      5024 non-null   object \n",
            " 1   director_name              4939 non-null   object \n",
            " 2   num_critic_for_reviews     4993 non-null   float64\n",
            " 3   duration                   5028 non-null   float64\n",
            " 4   director_facebook_likes    4939 non-null   float64\n",
            " 5   actor_3_facebook_likes     5020 non-null   float64\n",
            " 6   actor_2_name               5030 non-null   object \n",
            " 7   actor_1_facebook_likes     5036 non-null   float64\n",
            " 8   gross                      4159 non-null   float64\n",
            " 9   genres                     5043 non-null   object \n",
            " 10  actor_1_name               5036 non-null   object \n",
            " 11  movie_title                5043 non-null   object \n",
            " 12  num_voted_users            5043 non-null   int64  \n",
            " 13  cast_total_facebook_likes  5043 non-null   int64  \n",
            " 14  actor_3_name               5020 non-null   object \n",
            " 15  facenumber_in_poster       5030 non-null   float64\n",
            " 16  plot_keywords              4890 non-null   object \n",
            " 17  movie_imdb_link            5043 non-null   object \n",
            " 18  num_user_for_reviews       5022 non-null   float64\n",
            " 19  language                   5031 non-null   object \n",
            " 20  country                    5038 non-null   object \n",
            " 21  content_rating             4740 non-null   object \n",
            " 22  budget                     4551 non-null   float64\n",
            " 23  title_year                 4935 non-null   float64\n",
            " 24  actor_2_facebook_likes     5030 non-null   float64\n",
            " 25  imdb_score                 5043 non-null   float64\n",
            " 26  aspect_ratio               4714 non-null   float64\n",
            " 27  movie_facebook_likes       5043 non-null   int64  \n",
            "dtypes: float64(13), int64(3), object(12)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "color                         object\n",
            "director_name                 object\n",
            "num_critic_for_reviews       float64\n",
            "duration                     float64\n",
            "director_facebook_likes      float64\n",
            "actor_3_facebook_likes       float64\n",
            "actor_2_name                  object\n",
            "actor_1_facebook_likes       float64\n",
            "gross                        float64\n",
            "genres                        object\n",
            "actor_1_name                  object\n",
            "movie_title                   object\n",
            "num_voted_users                int64\n",
            "cast_total_facebook_likes      int64\n",
            "actor_3_name                  object\n",
            "facenumber_in_poster         float64\n",
            "plot_keywords                 object\n",
            "movie_imdb_link               object\n",
            "num_user_for_reviews         float64\n",
            "language                      object\n",
            "country                       object\n",
            "content_rating                object\n",
            "budget                       float64\n",
            "title_year                    object\n",
            "actor_2_facebook_likes       float64\n",
            "imdb_score                   float64\n",
            "aspect_ratio                 float64\n",
            "movie_facebook_likes           int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Example 4: Data Type conversion\n",
        "# Sometimes, especially when we’re reading in a CSV with a bunch of numbers, \n",
        "# some of the numbers will read in as strings instead of numeric values, or vice versa. \n",
        "# Let's fix the release year to be a string and not a number;\n",
        "# In pandas, the datatype string appears as object\n",
        "# \n",
        "\n",
        "# First let's see how our datatypes appear while loading the dataset\n",
        "data = pd.read_csv('http://bit.ly/MovieMetaData')\n",
        "print(data.info())\n",
        "\n",
        "# Now let's specify that our 'duration column needs to be an integer value'\n",
        "# Uncomment the lines below after running the previous lines\n",
        "data = pd.read_csv('http://bit.ly/MovieMetaData', dtype={'title_year': str})\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FQHRHC_QMJu"
      },
      "source": [
        "### <font color=\"green\">1.5 Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "awCjhzV1amoK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PID</th>\n",
              "      <th>Street number</th>\n",
              "      <th>Street name</th>\n",
              "      <th>Owner Occupied</th>\n",
              "      <th>No. of Bedrooms</th>\n",
              "      <th>No.of Bathrooms</th>\n",
              "      <th>Square Feet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100001000.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>PUTNAM</td>\n",
              "      <td>Y</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100002000.0</td>\n",
              "      <td>197.0</td>\n",
              "      <td>LEXINGTON</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>--</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100003000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LEXINGTON</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100004000.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>BERKELEY</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>203.0</td>\n",
              "      <td>BERKELEY</td>\n",
              "      <td>Y</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>100006000.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>BERKELEY</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100007000.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WASHINGTON</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>HURLEY</td>\n",
              "      <td>950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>100008000.0</td>\n",
              "      <td>213.0</td>\n",
              "      <td>TREMONT</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>100009000.0</td>\n",
              "      <td>215.0</td>\n",
              "      <td>TREMONT</td>\n",
              "      <td>Y</td>\n",
              "      <td>na</td>\n",
              "      <td>2</td>\n",
              "      <td>1800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           PID  Street number Street name Owner Occupied No. of Bedrooms  \\\n",
              "0  100001000.0          104.0      PUTNAM              Y               3   \n",
              "1  100002000.0          197.0   LEXINGTON              N               3   \n",
              "2  100003000.0            NaN   LEXINGTON              N             NaN   \n",
              "3  100004000.0          201.0    BERKELEY             12               1   \n",
              "4          NaN          203.0    BERKELEY              Y               3   \n",
              "5  100006000.0          207.0    BERKELEY              Y             NaN   \n",
              "6  100007000.0            NaN  WASHINGTON            NaN               2   \n",
              "7  100008000.0          213.0     TREMONT              Y               1   \n",
              "8  100009000.0          215.0     TREMONT              Y              na   \n",
              "\n",
              "  No.of Bathrooms Square Feet  \n",
              "0               1        1000  \n",
              "1             1.5          --  \n",
              "2               1         850  \n",
              "3             NaN         700  \n",
              "4               2        1600  \n",
              "5               1         800  \n",
              "6          HURLEY         950  \n",
              "7               1         NaN  \n",
              "8               2        1800  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Challenge 1\n",
        "# Rename and fix the columns names of the following dataset\n",
        "# url = http://bit.ly/MSPropertyDataset\n",
        "# Columns = Street number, Street name, Owner Occupied, No. of Bedrooms\n",
        "# \n",
        "data = pd.read_csv(\"http://bit.ly/MSPropertyDataset\")\n",
        "data\n",
        "data.columns = ['PID','Street number','Street name','Owner Occupied','No. of Bedrooms','No.of Bathrooms','Square Feet']\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "HvBMDobHdH9v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Date    3 non-null      object\n",
            " 1   Event   3 non-null      object\n",
            " 2   Cost    3 non-null      int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 200.0+ bytes\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   Date    3 non-null      datetime64[ns]\n",
            " 1   Event   3 non-null      object        \n",
            " 2   Cost    3 non-null      int64         \n",
            "dtypes: datetime64[ns](1), int64(1), object(1)\n",
            "memory usage: 200.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "# Challenge 2\n",
        "# Convert the following dataframe column Data from string to datetime format\n",
        "# \n",
        "\n",
        "schedule_df = pd.DataFrame({'Date':['23/9/2011', '11/4/2010', '10/12/2019'], \n",
        "                'Event':['Music', 'Drama', 'Arts'], \n",
        "                'Cost':[17000, 55000, 25000]}) \n",
        "\n",
        "schedule_df.info()\n",
        "schedule_df['Date'] = pd.to_datetime(schedule_df['Date'])\n",
        "schedule_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "wOVxciRxQRHU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype         \n",
            "---  ------           --------------  -----         \n",
            " 0   Customer Number  5 non-null      int32         \n",
            " 1   Customer Name    5 non-null      object        \n",
            " 2   2016             5 non-null      float64       \n",
            " 3   2017             5 non-null      float64       \n",
            " 4   Percent Growth   5 non-null      float64       \n",
            " 5   Jan Units        5 non-null      object        \n",
            " 6   Month            5 non-null      datetime64[ns]\n",
            " 7   Day              5 non-null      datetime64[ns]\n",
            " 8   Year             5 non-null      datetime64[ns]\n",
            " 9   Active           5 non-null      bool          \n",
            "dtypes: bool(1), datetime64[ns](3), float64(3), int32(1), object(2)\n",
            "memory usage: 473.0+ bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\MARCHE~1\\AppData\\Local\\Temp/ipykernel_2300/3843824722.py:18: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  sales_df['2016']=sales_df['2016'].str.replace('$','')\n",
            "C:\\Users\\MARCHE~1\\AppData\\Local\\Temp/ipykernel_2300/3843824722.py:21: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  sales_df['2017']=sales_df['2017'].str.replace('$','')\n"
          ]
        }
      ],
      "source": [
        "# Challenge 3\n",
        "# Work on converting the following data types from the given sales dataset\n",
        "# url = http://bit.ly/SalesDataset\n",
        "# - The Customer Number is a float64 but it should be an int64\n",
        "# - The 2016 and 2017 columns are stored as objects, not numerical values such as a float64 or int64\n",
        "# - Percent Growth and Jan Units are also stored as objects not numerical values\n",
        "# - Month, Day and Year columns that should be converted to datetime64\n",
        "# - Active column should be a boolean\n",
        "# We cannot work with this dataset until we clean up normalize the datatypes \n",
        "# A good example of this would be if we were to perform the following operation \n",
        "#\n",
        "\n",
        "# Loading our sales dataset\n",
        "sales_df = pd.read_csv(\"http://bit.ly/SalesDataset\")\n",
        "sales_df['Customer Number'] = sales_df['Customer Number'].astype(int)\n",
        "# and then perform some operation reveals a problem\n",
        "#sales_df['2016'] + sales_df['2017'] \n",
        "sales_df['2016']=sales_df['2016'].str.replace('$','')\n",
        "sales_df['2016']=sales_df['2016'].str.replace(',','')\n",
        "sales_df\n",
        "sales_df['2017']=sales_df['2017'].str.replace('$','')\n",
        "sales_df['2017']=sales_df['2017'].str.replace(',','')\n",
        "sales_df\n",
        "sales_df['2016'] = pd.to_numeric(sales_df['2016'])\n",
        "sales_df['2017'] = pd.to_numeric(sales_df['2017'])\n",
        "\n",
        "# Performing our conversion below\n",
        "sales_df['Percent Growth'] = sales_df['Percent Growth'].str.replace('%','')\n",
        "sales_df['Percent Growth'] = pd.to_numeric(sales_df['Percent Growth'])\n",
        "\n",
        "# sales_df.loc[sales_df['Jan Units']=='closed'] = 0\n",
        "sales_df['Month'] = pd.to_datetime(sales_df['Month'])\n",
        "sales_df['Day'] = pd.to_datetime(sales_df['Day'])\n",
        "sales_df['Year'] = pd.to_datetime(sales_df['Year'])\n",
        "sales_df['Active'] = sales_df['Active'].astype(bool)\n",
        "#sales_df['Jan Units'] = pd.to_numeric(sales_df['Jan Units'])\n",
        "sales_df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "f0LiYra_ZGrf",
        "zMDkx0IpxCCR",
        "Y7Dgv6QeG-tw",
        "zxpZyP9yxlzl",
        "PQ8DPOj4HGtQ",
        "vPXKeupMxvT3",
        "KSSnxqGcH4pc",
        "Wus-RyPhx2k2",
        "vvxGZOoWXnmy",
        "o59W2bFhx_8k",
        "1FQHRHC_QMJu"
      ],
      "name": "Python Data Cleaning: Basics II",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
